{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anuunchinbat/Desktop/Thesis/myenv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow_model_optimization as tfmot\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Normalize to [0, 1]\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "# Reshape\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2515 - accuracy: 0.9286 - val_loss: 0.1326 - val_accuracy: 0.9597\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 2s 926us/step - loss: 0.1100 - accuracy: 0.9679 - val_loss: 0.0983 - val_accuracy: 0.9695\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 2s 901us/step - loss: 0.0745 - accuracy: 0.9782 - val_loss: 0.0948 - val_accuracy: 0.9706\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 2s 909us/step - loss: 0.0562 - accuracy: 0.9822 - val_loss: 0.0805 - val_accuracy: 0.9747\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 2s 911us/step - loss: 0.0426 - accuracy: 0.9868 - val_loss: 0.0709 - val_accuracy: 0.9767\n",
      "313/313 [==============================] - 0s 611us/step - loss: 0.0709 - accuracy: 0.9767\n",
      "Baseline Test Accuracy: 0.9767000079154968\n",
      "INFO:tensorflow:Assets written to: ./saved_unquantized_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved_unquantized_model/assets\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Flatten(input_shape=(28, 28, 1)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test))\n",
    "\n",
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "print(f'Baseline Test Accuracy: {accuracy}')\n",
    "\n",
    "model.save(\"./saved_unquantized_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weigths:  784\n",
      "biases:  128\n",
      "weigths:  128\n",
      "biases:  10\n",
      "{'dense': {'weights_min_max': (-0.92499673, 0.5262218), 'bias_min_max': (-0.16946252, 0.2295666)}, 'dense_1': {'weights_min_max': (-0.9400578, 0.7109961), 'bias_min_max': (-0.095205545, 0.1373023)}}\n"
     ]
    }
   ],
   "source": [
    "def get_min_max(weights):\n",
    "    min_val = np.min(weights)\n",
    "    max_val = np.max(weights)\n",
    "    return min_val, max_val\n",
    "\n",
    "weight_min_max = {}\n",
    "\n",
    "for i, layer in enumerate(model.layers):\n",
    "    if len(layer.get_weights()) > 0: #the flatten layer doesn't have weigts\n",
    "        weights = layer.get_weights()[0]\n",
    "        print(\"weigths: \", len(weights)) #28x28 input flattened into a vector\n",
    "        bias = layer.get_weights()[1] # number of neurons - output neurons in second layer\n",
    "        print(\"biases: \", len(bias))\n",
    "        weight_min_max[layer.name] = {\n",
    "            'weights_min_max': get_min_max(weights),\n",
    "            'bias_min_max': get_min_max(bias)\n",
    "        }\n",
    "\n",
    "print(weight_min_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize(weights, min_val, max_val, num_bits=8): #[0,255]\n",
    "    scale = (max_val - min_val) / (2 ** num_bits - 1) #255 max\n",
    "    zero_point = np.round(-min_val / scale) #0 = round(min_val / scale + zero_point)\n",
    "    quantized_weights = np.round(weights / scale + zero_point)\n",
    "    return quantized_weights, scale, zero_point\n",
    "\n",
    "def symmetrically_quantize(weights, min_val, max_val, num_bits=8): #[-128, 127]\n",
    "    scale = (max_val - min_val) / (2 ** num_bits - 1)    \n",
    "    zero_point = 0\n",
    "    quantized_weights = np.round(weights / scale)    \n",
    "    quantized_weights = np.clip(quantized_weights, -(2 ** (num_bits - 1)), (2 ** (num_bits - 1)) - 1) #due to scaling and rounding, some quantized value falls outside this range    \n",
    "    return quantized_weights, scale, zero_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantized weights keys: dict_keys(['dense', 'dense_1'])\n",
      "Scales keys: dict_keys(['dense', 'dense_1'])\n"
     ]
    }
   ],
   "source": [
    "# Quantize the weights\n",
    "quantized_weights = {}\n",
    "scales = {}\n",
    "zero_points = {}\n",
    "\n",
    "for layer in model.layers:\n",
    "    if len(layer.get_weights()) > 0: #the flatten layer doesn't have weigts\n",
    "        weights = layer.get_weights()[0]\n",
    "        bias = layer.get_weights()[1]\n",
    "        \n",
    "        w_min, w_max = weight_min_max[layer.name]['weights_min_max']\n",
    "        b_min, b_max = weight_min_max[layer.name]['bias_min_max']\n",
    "        \n",
    "        #q_weights, w_scale, w_zero_point = quantize(weights, w_min, w_max)\n",
    "        #q_bias, b_scale, b_zero_point = quantize(bias, b_min, b_max)\n",
    "        \n",
    "        q_weights, w_scale, w_zero_point = symmetrically_quantize(weights, w_min, w_max)\n",
    "        q_bias, b_scale, b_zero_point = symmetrically_quantize(bias, b_min, b_max)\n",
    "\n",
    "        quantized_weights[layer.name] = {\n",
    "            'quantized_weights': q_weights,\n",
    "            'quantized_bias': q_bias\n",
    "        }\n",
    "        scales[layer.name] = {\n",
    "            'weights_scale': w_scale,\n",
    "            'bias_scale': b_scale\n",
    "        }\n",
    "        zero_points[layer.name] = {\n",
    "            'weights_zero_point': w_zero_point,\n",
    "            'bias_zero_point': b_zero_point\n",
    "        }\n",
    "\n",
    "print(\"Quantized weights keys:\", quantized_weights.keys())\n",
    "print(\"Scales keys:\", scales.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dequantize(q_weights, scale, zero_point):\n",
    "    return (q_weights - zero_point) * scale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantizedDense(tf.keras.layers.Layer):\n",
    "    def __init__(self, units, quantized_weights, scales, zero_points, activation=None):\n",
    "        super(QuantizedDense, self).__init__()\n",
    "        self.units = units\n",
    "        self.quantized_weights = quantized_weights\n",
    "        self.scales = scales\n",
    "        self.zero_points = zero_points\n",
    "        self.activation = activation\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        self.quantized_bias = self.add_weight(name='quantized_bias', shape=(self.units,), initializer='zeros', trainable=False)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        q_weights = self.quantized_weights\n",
    "        w_scale = self.scales['weights_scale']\n",
    "        w_zero_point = self.zero_points['weights_zero_point']\n",
    "        \n",
    "        w = dequantize(q_weights, w_scale, w_zero_point)\n",
    "        b = dequantize(self.quantized_bias, self.scales['bias_scale'], self.zero_points['bias_zero_point'])\n",
    "        \n",
    "        output = tf.matmul(inputs, w) + b\n",
    "        \n",
    "        if self.activation is not None:\n",
    "            output = self.activation(output)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 2s 782us/step - loss: 0.0283 - accuracy: 0.9922 - val_loss: 0.0697 - val_accuracy: 0.9773\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 1s 685us/step - loss: 0.0283 - accuracy: 0.9922 - val_loss: 0.0697 - val_accuracy: 0.9773\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 1s 686us/step - loss: 0.0283 - accuracy: 0.9922 - val_loss: 0.0697 - val_accuracy: 0.9773\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 1s 718us/step - loss: 0.0283 - accuracy: 0.9922 - val_loss: 0.0697 - val_accuracy: 0.9773\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 1s 773us/step - loss: 0.0283 - accuracy: 0.9922 - val_loss: 0.0697 - val_accuracy: 0.9773\n",
      "313/313 [==============================] - 0s 594us/step - loss: 0.0697 - accuracy: 0.9773\n",
      "Quantized Model Test Accuracy: 0.9772999882698059\n"
     ]
    }
   ],
   "source": [
    "# Create a new model with quantized layers\n",
    "quantized_model = tf.keras.Sequential([\n",
    "    Flatten(input_shape=(28, 28, 1)),\n",
    "    QuantizedDense(128, quantized_weights['dense']['quantized_weights'], scales['dense'], zero_points['dense'], activation=tf.nn.relu),\n",
    "    QuantizedDense(10, quantized_weights['dense_1']['quantized_weights'], scales['dense_1'], zero_points['dense_1'], activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "quantized_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "quantized_model.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test))\n",
    "\n",
    "loss, accuracy = quantized_model.evaluate(x_test, y_test)\n",
    "print(f'Quantized Model Test Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
